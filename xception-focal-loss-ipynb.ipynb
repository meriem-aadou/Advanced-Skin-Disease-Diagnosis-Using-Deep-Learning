{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11183147,"sourceType":"datasetVersion","datasetId":6980572}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install split-folders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:00:26.215753Z","iopub.execute_input":"2025-04-02T07:00:26.216084Z","iopub.status.idle":"2025-04-02T07:00:31.052535Z","shell.execute_reply.started":"2025-04-02T07:00:26.216060Z","shell.execute_reply":"2025-04-02T07:00:31.051473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport glob\nimport PIL\nimport pathlib\nimport splitfolders\nimport random\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, MaxPooling2D, Flatten, BatchNormalization\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:00:31.053771Z","iopub.execute_input":"2025-04-02T07:00:31.054031Z","iopub.status.idle":"2025-04-02T07:00:44.825487Z","shell.execute_reply.started":"2025-04-02T07:00:31.054001Z","shell.execute_reply":"2025-04-02T07:00:44.824584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"splitfolders.ratio(\"/kaggle/input/thesisdataset/thesdats\",\n                   output=\"/kaggle/working/dataset_split\",\n                   ratio=(0.7, 0.15, 0.15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:00:44.827487Z","iopub.execute_input":"2025-04-02T07:00:44.828002Z","iopub.status.idle":"2025-04-02T07:01:50.947816Z","shell.execute_reply.started":"2025-04-02T07:00:44.827967Z","shell.execute_reply":"2025-04-02T07:01:50.947049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir_train = pathlib.Path( '/kaggle/working/dataset_split/train')\nimg_height,  img_width  = 299, 299","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:50.949068Z","iopub.execute_input":"2025-04-02T07:01:50.949318Z","iopub.status.idle":"2025-04-02T07:01:50.953065Z","shell.execute_reply.started":"2025-04-02T07:01:50.949300Z","shell.execute_reply":"2025-04-02T07:01:50.952250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = image_dataset_from_directory(data_dir_train,\n                                        seed = 123,\n                                        image_size=(img_height, img_width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:50.953764Z","iopub.execute_input":"2025-04-02T07:01:50.954024Z","iopub.status.idle":"2025-04-02T07:01:54.123625Z","shell.execute_reply.started":"2025-04-02T07:01:50.954003Z","shell.execute_reply":"2025-04-02T07:01:54.122937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_ds.class_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:54.124486Z","iopub.execute_input":"2025-04-02T07:01:54.124806Z","iopub.status.idle":"2025-04-02T07:01:54.128406Z","shell.execute_reply.started":"2025-04-02T07:01:54.124771Z","shell.execute_reply":"2025-04-02T07:01:54.127389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:54.129592Z","iopub.execute_input":"2025-04-02T07:01:54.129907Z","iopub.status.idle":"2025-04-02T07:01:54.145033Z","shell.execute_reply.started":"2025-04-02T07:01:54.129878Z","shell.execute_reply":"2025-04-02T07:01:54.144270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Visualizing the training data\nplt.figure(figsize=(15, 10))\n\nfor i, class_ in enumerate(list(class_names)):\n    plt.subplot(3, 3, i+1)\n\n    # Correct indentation for the following lines\n    data_path = os.path.join(str(data_dir_train), class_)\n    file_paths = glob.glob(os.path.join(data_path, '*.*'))\n    random_img_path = random.choice(file_paths)\n    img = PIL.Image.open(random_img_path)\n    plt.imshow(img)\n    plt.title(class_)\n    plt.axis(\"off\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:54.145929Z","iopub.execute_input":"2025-04-02T07:01:54.146132Z","iopub.status.idle":"2025-04-02T07:01:54.944142Z","shell.execute_reply.started":"2025-04-02T07:01:54.146114Z","shell.execute_reply":"2025-04-02T07:01:54.943106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_size = {}\nfor name in class_names:\n    class_size[name] = len(list(data_dir_train.glob(name+'/*.*')))\n\nclass_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:54.946724Z","iopub.execute_input":"2025-04-02T07:01:54.947013Z","iopub.status.idle":"2025-04-02T07:01:54.969970Z","shell.execute_reply.started":"2025-04-02T07:01:54.946991Z","shell.execute_reply":"2025-04-02T07:01:54.969345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_df = pd.DataFrame(class_size.items(),index=list(class_size), columns = ['ClassName', 'NumberOfSamples'])\nclass_df.drop(['ClassName'], axis = 1, inplace=True)\nclass_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:54.971428Z","iopub.execute_input":"2025-04-02T07:01:54.971638Z","iopub.status.idle":"2025-04-02T07:01:55.000182Z","shell.execute_reply.started":"2025-04-02T07:01:54.971616Z","shell.execute_reply":"2025-04-02T07:01:54.999419Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Augmentation**","metadata":{}},{"cell_type":"code","source":"!pip install Augmentor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:55.001093Z","iopub.execute_input":"2025-04-02T07:01:55.001455Z","iopub.status.idle":"2025-04-02T07:01:58.854571Z","shell.execute_reply.started":"2025-04-02T07:01:55.001430Z","shell.execute_reply":"2025-04-02T07:01:58.853598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import Augmentor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:58.855638Z","iopub.execute_input":"2025-04-02T07:01:58.855983Z","iopub.status.idle":"2025-04-02T07:01:58.876664Z","shell.execute_reply.started":"2025-04-02T07:01:58.855943Z","shell.execute_reply":"2025-04-02T07:01:58.876039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\npath_to_training_dataset = '/kaggle/working/dataset_split/train/'\ntarget_samples = 1500  # Desired number of samples per class\n\nfor i in class_names:\n    class_path = os.path.join(path_to_training_dataset, i)\n    existing_samples = len(os.listdir(class_path))  # Count existing images\n    additional_samples = max(0, target_samples - existing_samples)  # Calculate needed samples\n\n    if additional_samples > 0:\n        p = Augmentor.Pipeline(class_path, output_directory='')\n\n        # 1. Extreme Rotation\n        p.rotate(probability=0.9, max_left_rotation=25, max_right_rotation=25)\n\n        # 2. Horizontal & Vertical Flip\n        p.flip_left_right(probability=0.8)\n        p.flip_top_bottom(probability=0.5)\n\n        # 3. Random Zoom\n        p.zoom_random(probability=0.7, percentage_area=0.5)\n\n        # 4. Random Brightness\n        p.random_brightness(probability=0.8, min_factor=0.4, max_factor=1.8)\n\n        # 5. Random Contrast\n        p.random_contrast(probability=0.7, min_factor=0.3, max_factor=2.0)\n\n        # 6. Random Distortions (Mimics warping)\n        p.random_distortion(probability=0.7, grid_width=6, grid_height=6, magnitude=12)\n\n        # 7. Shearing\n        p.shear(probability=0.6, max_shear_left=20, max_shear_right=20)\n\n        # 8. Skewing\n        p.skew(probability=0.6, magnitude=0.5)\n\n        # 9. Gaussian Noise\n        p.gaussian_distortion(probability=0.6, grid_width=5, grid_height=5, magnitude=8, corner='bell', method='in')\n\n        # 10. Greyscale Conversion (Black & White Effect)\n        p.greyscale(probability=0.4)\n\n        # 11. Inversion (Negative Effect)\n        p.invert(probability=0.3)\n\n        # 12. Crop & Resize (For additional variation)\n        p.crop_random(probability=0.5, percentage_area=0.7)\n        p.resize(probability=1.0, width=128, height=128)\n\n      \n\n        # Generate only the necessary number of images\n        p.sample(additional_samples)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:01:58.877448Z","iopub.execute_input":"2025-04-02T07:01:58.877723Z","iopub.status.idle":"2025-04-02T07:04:31.032797Z","shell.execute_reply.started":"2025-04-02T07:01:58.877692Z","shell.execute_reply":"2025-04-02T07:04:31.031923Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"batch_size = 32\nepochs = 50\nimg_size = 224","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.033814Z","iopub.execute_input":"2025-04-02T07:04:31.034210Z","iopub.status.idle":"2025-04-02T07:04:31.038320Z","shell.execute_reply.started":"2025-04-02T07:04:31.034175Z","shell.execute_reply":"2025-04-02T07:04:31.037350Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_datagen = ImageDataGenerator( rescale=1./255,\n                                  rotation_range=5,  # rotation\n                                   width_shift_range=0.2,  # horizontal shift\n                                   zoom_range=0.2,  # zoom\n                                   horizontal_flip=True,\n                               # horizontal flip\n                                   brightness_range=[0.2,0.8])\n\ntest_datagen = ImageDataGenerator(\n                                   rescale=1./255,\n                                   rotation_range=5,  # rotation\n                                   width_shift_range=0.2,  # horizontal shift\n                                   zoom_range=0.2,  # zoom\n                                   horizontal_flip=True,  # horizontal flip\n                                   brightness_range=[0.2,0.8])\ntraining_set = train_datagen.flow_from_directory('/kaggle/working/dataset_split/train',\n                                               target_size=(224,224),\n                                                 batch_size=32)\n\ntest_set = test_datagen.flow_from_directory('/kaggle/working/dataset_split/val',\n                                            target_size=(224,224),\n                                            batch_size=32,\n                                            shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.039248Z","iopub.execute_input":"2025-04-02T07:04:31.039551Z","iopub.status.idle":"2025-04-02T07:04:31.236505Z","shell.execute_reply.started":"2025-04-02T07:04:31.039520Z","shell.execute_reply":"2025-04-02T07:04:31.235915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Focal Loss Definition (better for imbalanced data)\n\nimport tensorflow.keras.backend as K\nimport tensorflow as tf\n# Update focal_loss to point to the function focal_loss_fixed\ndef focal_loss(gamma=2., alpha=[0.25, 0.40, 0.20, 0.15, 0.20]):\n    # Convert alpha to a tensor for computation\n    alpha = K.constant(alpha)\n\n    def focal_loss_fixed(y_true, y_pred):\n        # Clip predictions to prevent log(0)\n        y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())\n\n        # Calculate cross-entropy\n        cross_entropy = -y_true * K.log(y_pred)\n\n        # Compute weights for each class\n        weight = alpha * K.pow(1 - y_pred, gamma)\n\n        # Apply the weights to the cross-entropy\n        loss = K.sum(weight * cross_entropy, axis=-1)\n\n        # Return mean loss across the batch (for better stability during training)\n        return K.mean(loss)\n\n    return focal_loss_fixed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.237209Z","iopub.execute_input":"2025-04-02T07:04:31.237406Z","iopub.status.idle":"2025-04-02T07:04:31.244074Z","shell.execute_reply.started":"2025-04-02T07:04:31.237388Z","shell.execute_reply":"2025-04-02T07:04:31.243269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Xception():\n\n    engine = tf.keras.applications.Xception(\n        # Freezing the weights of the top layer in the InceptionResNetV2 pre-traiined model\n        include_top = False,\n\n        # Use Imagenet weights\n        weights = 'imagenet',\n\n        # Define input shape to 299x299x3\n        input_shape = (img_size , img_size , 3),\n\n    )\n\n\n    x = tf.keras.layers.GlobalAveragePooling2D(name = 'avg_pool')(engine.output)\n    x =Dropout(0.75)(x)\n    x = tf.keras.layers.BatchNormalization(\n                      axis=-1,\n                      momentum=0.99,\n                      epsilon=0.01,\n                      center=True,\n                      scale=True,\n                      beta_initializer=\"zeros\",\n                      gamma_initializer=\"ones\",\n                      moving_mean_initializer=\"zeros\",\n                      moving_variance_initializer=\"ones\",\n                      beta_regularizer=None,\n                      gamma_regularizer=None,\n                      beta_constraint=None,\n                      gamma_constraint=None,\n\n                  )(x)\n\n    out = tf.keras.layers.Dense(5,\n                                activation = 'softmax',\n                                kernel_regularizer=regularizers.l2(0.02) ,\n                                name = 'dense_output'\n                                )(x)\n\n\n    # Build the Keras model\n\n    model = tf.keras.models.Model(inputs = engine.input, outputs = out)\n    # Compile the model\n\n    model.compile(\n        # Set optimizer to Adam(0.0001)\n        optimizer = tf.keras.optimizers.Adam(learning_rate= 3e-4),\n        # Set loss to focal loss\n        loss=focal_loss(gamma=2.0, alpha=[0.25, 0.40, 0.20, 0.15, 0.20]),\n        # Set metrics to accuracy\n        metrics = ['accuracy']\n    )\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.245022Z","iopub.execute_input":"2025-04-02T07:04:31.245326Z","iopub.status.idle":"2025-04-02T07:04:31.258193Z","shell.execute_reply.started":"2025-04-02T07:04:31.245295Z","shell.execute_reply":"2025-04-02T07:04:31.257429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\nlearning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n                                                            patience=3,\n                                                            verbose=2,\n                                                            factor=0.5,\n                                                            min_lr=0.00001)\nreduce_lr =  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                              patience=4, min_lr=0.00001)\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.258998Z","iopub.execute_input":"2025-04-02T07:04:31.259326Z","iopub.status.idle":"2025-04-02T07:04:31.273406Z","shell.execute_reply.started":"2025-04-02T07:04:31.259295Z","shell.execute_reply":"2025-04-02T07:04:31.272512Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filepath = '/kaggle/working/checkpoint/mymodel-best.keras'\ncheckpoint = ModelCheckpoint(filepath , save_best_only= True, monitor = 'val_accuracy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.274303Z","iopub.execute_input":"2025-04-02T07:04:31.274581Z","iopub.status.idle":"2025-04-02T07:04:31.288104Z","shell.execute_reply.started":"2025-04-02T07:04:31.274553Z","shell.execute_reply":"2025-04-02T07:04:31.287310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/Models/categories/', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.289028Z","iopub.execute_input":"2025-04-02T07:04:31.289332Z","iopub.status.idle":"2025-04-02T07:04:31.299450Z","shell.execute_reply.started":"2025-04-02T07:04:31.289309Z","shell.execute_reply":"2025-04-02T07:04:31.298675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport time\n\ndef train():\n    time_start = time.time()\n\n    model = Xception()\n\n    model.summary()\n\n    \n    history = model.fit(\n        training_set,\n        epochs=50,\n        validation_data=test_set,\n        callbacks=[early_stopping , learning_rate_reduction, checkpoint]\n    )\n\n    model.save_weights('/kaggle/working/Models/categories/category.weights.h5')\n    model.save('/kaggle/working/Models/categories/category.h5')\n\n    print('Model saved.')\n\n    time_end = time.time()\n    print('Training Time:', time_end - time_start)\n    print('\\n')\n\n    return history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.300316Z","iopub.execute_input":"2025-04-02T07:04:31.300561Z","iopub.status.idle":"2025-04-02T07:04:31.310562Z","shell.execute_reply.started":"2025-04-02T07:04:31.300542Z","shell.execute_reply":"2025-04-02T07:04:31.309900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test():\n    #test_labels = np.array(test_labels)\n\n    from tensorflow import keras\n    print('Testing:')\n    mod = keras.models.load_model('/kaggle/working/Models/categories/category.h5', custom_objects={'focal_loss_fixed': focal_loss()})\n    mod.evaluate(test_set)\n\n    prob = mod.predict(test_set)\n    predIdxs = np.argmax(prob, axis=1)\n\n\n    print('\\n')\n    print(classification_report(test_set.labels, predIdxs,target_names = key, digits=5))\n    return  prob, predIdxs, mod","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.311368Z","iopub.execute_input":"2025-04-02T07:04:31.311658Z","iopub.status.idle":"2025-04-02T07:04:31.323538Z","shell.execute_reply.started":"2025-04-02T07:04:31.311629Z","shell.execute_reply":"2025-04-02T07:04:31.322863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_path = '/kaggle/working/dataset_split/val'\ntrain_data = image_dataset_from_directory(directory=input_path,\n                                              batch_size=32,\n                                              image_size=(299, 299))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.324265Z","iopub.execute_input":"2025-04-02T07:04:31.324570Z","iopub.status.idle":"2025-04-02T07:04:31.421639Z","shell.execute_reply.started":"2025-04-02T07:04:31.324539Z","shell.execute_reply":"2025-04-02T07:04:31.420986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['accuracy'], label='Training Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.legend()\n\n    plt.show()\n\nif __name__ == \"__main__\":\n    key = train_data.class_names\n    train_history = train()\n    prob, predIdxs, model = test()\n\n    # Plot training history\n    plot_training_history(train_history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:04:31.422350Z","iopub.execute_input":"2025-04-02T07:04:31.422593Z","iopub.status.idle":"2025-04-02T09:25:30.300105Z","shell.execute_reply.started":"2025-04-02T07:04:31.422572Z","shell.execute_reply":"2025-04-02T09:25:30.299203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define test data generator for final testing\nfinal_test_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load final test set\nfinal_test_set = final_test_datagen.flow_from_directory('/kaggle/working/dataset_split/test/',\n                                                        target_size=(224, 224),\n                                                        batch_size=32,\n                                                        shuffle=False)  \n\n# Load the model\nmod = keras.models.load_model('/kaggle/working/Models/categories/category.h5', custom_objects={'focal_loss_fixed': focal_loss()})\n \n# Evaluate the model on the final test set\nfinal_test_loss, final_test_accuracy = mod.evaluate(final_test_set)\nprint(f'Final Test Loss: {final_test_loss}')\nprint(f'Final Test Accuracy: {final_test_accuracy}')\n\n# Predicting and classification report\nprob = model.predict(final_test_set)\npredIdxs = np.argmax(prob, axis=1)\n\n# Get class names from class indices\nclass_names = list(final_test_set.class_indices.keys())\n\n# Print classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(final_test_set.classes, predIdxs, target_names=class_names))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:25:30.301062Z","iopub.execute_input":"2025-04-02T09:25:30.301326Z","iopub.status.idle":"2025-04-02T09:26:00.981852Z","shell.execute_reply.started":"2025-04-02T09:25:30.301305Z","shell.execute_reply":"2025-04-02T09:26:00.980719Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" #Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Generate confusion matrix\nconf_matrix = confusion_matrix(final_test_set.classes, predIdxs)\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='RdPu', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T09:26:00.983139Z","iopub.execute_input":"2025-04-02T09:26:00.983546Z","iopub.status.idle":"2025-04-02T09:26:01.603640Z","shell.execute_reply.started":"2025-04-02T09:26:00.983508Z","shell.execute_reply":"2025-04-02T09:26:01.602697Z"}},"outputs":[],"execution_count":null}]}